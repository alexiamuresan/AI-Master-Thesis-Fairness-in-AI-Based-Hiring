{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fef75f70-b342-4221-9b5d-eda92af1a348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "data = pd.read_csv('Data/balanced_resumes.csv')\n",
    "\n",
    "# drop rows with missing values in text columns\n",
    "text_columns = ['Name', 'Education', 'Work Experience', 'Skills', 'Awards']\n",
    "data = data.dropna(subset=text_columns)\n",
    "\n",
    "# extract text data and labels\n",
    "X_text = data['Name'] + ' ' + data['Education'] + ' ' + data['Work Experience'] + ' ' + data['Skills'] + ' ' + data['Awards']\n",
    "y = data['Fit']\n",
    "gender = data['Gender']\n",
    "ethnicity = data ['Ethnicity']\n",
    "\n",
    "# vectorize the text data with TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_text_vec = vectorizer.fit_transform(X_text)\n",
    "\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test, gender_train, gender_test, ethnicity_train, ethnicity_test = train_test_split(X_text_vec, y, gender, ethnicity, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5b8699f-76bc-46ee-a46e-cc91d9c70ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of support vectors: 957\n",
      "Number of features: 3893\n",
      "Total number of trainable parameters: 3725606\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "svm_classifier = SVC(kernel='linear', C=1.7) \n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "y_pred_svm = svm_classifier.predict(X_test)\n",
    "\n",
    "# nr of support vectors\n",
    "n_support_vectors = len(svm_classifier.support_)\n",
    "\n",
    "# nr of features per support vector\n",
    "n_features = X_train.shape[1]\n",
    "\n",
    "# total number of parameters = (number of support vectors * number of features) + bias term\n",
    "total_params = n_support_vectors * n_features + len(svm_classifier.classes_)\n",
    "\n",
    "print(f\"Number of support vectors: {n_support_vectors}\")\n",
    "print(f\"Number of features: {n_features}\")\n",
    "print(f\"Total number of trainable parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e1ffa50-4a4d-4ccd-8f47-4b20a423ebe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 3893\n",
      "Total number of trainable parameters: 3894\n"
     ]
    }
   ],
   "source": [
    "# train the Logistic Regression classifier\n",
    "\n",
    "logistic_classifier = LogisticRegression(max_iter=1000)\n",
    "logistic_classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "y_pred_lr = logistic_classifier.predict(X_test)\n",
    "\n",
    "# nr of features (terms in TF-IDF)\n",
    "n_features = X_train.shape[1]\n",
    "\n",
    "# nr of parameters (coefficients + intercept)\n",
    "total_params = n_features + 1\n",
    "\n",
    "print(f\"Number of features: {n_features}\")\n",
    "print(f\"Total number of trainable parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09d3d8ca-04be-4ca3-9c1d-5fa8079d91db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of estimators (trees) in the forest: 90\n",
      "Maximum depth of trees: 54\n",
      "Approximate trainable parameters in the Random Forest: 37839960\n"
     ]
    }
   ],
   "source": [
    "# train Random Forest\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=90)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "n_estimators = 90\n",
    "max_depth = 54\n",
    "\n",
    "# Approximate calculation of trainable parameters\n",
    "approx_params_per_tree = 2 * max_depth * num_features  # Assuming a rough estimate\n",
    "total_trainable_params = n_estimators * approx_params_per_tree\n",
    "\n",
    "print(f\"Number of estimators (trees) in the forest: {n_estimators}\")\n",
    "print(f\"Maximum depth of trees: {max_depth}\")\n",
    "print(f\"Approximate trainable parameters in the Random Forest: {total_trainable_params}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1391d6f3-0313-4b63-821b-cdc78832848e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of estimators (trees) in the ensemble: 90\n",
      "Maximum depth of trees: 3\n",
      "Approximate trainable parameters in the Gradient Boosting model: 90000\n"
     ]
    }
   ],
   "source": [
    "# train Gradient Boosting classifier\n",
    "\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=90)  \n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "y_pred_gb = gb_classifier.predict(X_test)\n",
    "\n",
    "# estimating trainable parameters\n",
    "num_features = X_train.shape[1]\n",
    "n_estimators = gb_classifier.n_estimators_\n",
    "max_depth = gb_classifier.max_depth\n",
    "\n",
    "# estimate of params per tree\n",
    "params_per_tree = 1000 \n",
    "\n",
    "total_trainable_params = n_estimators * params_per_tree\n",
    "\n",
    "\n",
    "print(f\"Number of estimators (trees) in the ensemble: {n_estimators}\")\n",
    "print(f\"Maximum depth of trees: {max_depth}\")\n",
    "print(f\"Approximate trainable parameters in the Gradient Boosting model: {total_trainable_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efde0bc-38d0-40b5-a84d-c51334d6e570",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
